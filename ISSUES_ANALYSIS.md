# Project Analysis - Inventory and Issues (Read-Only)

This document inventories the codebase and documents all observed issues across networking, AI, messaging, and real-time layers. No fixes are proposed here.

## Phase 1. Codebase Inventory

- Application type: React (client) + Node/Express (server) + workers
- Key directories:
  - `client/src/`: React app, chat interfaces, VNC, websocket client, query client
  - `server/`: Express production server, routes, AI integration, websocket modules, automation
  - `ollama-service/`: Dockerfile for Ollama service
  - `worker/`: background workers, VNC manager
- Config/build:
  - `package.json`: deps include `socket.io`, `ws`, `ollama`, `express`, `@tanstack/react-query`
  - `nixpacks.toml`: installs curl and system libs
  - `ollama-service/Dockerfile`: pulls tinyllama:latest
  - `railway-test.json`: test deployment config (not primary)

### Dependencies (selected)
- Realtime: `socket.io@^4.8.1`, `ws@^8.18.3`
- AI: `ollama@^0.5.0`
- Server: `express@^4.21.2`
- Frontend: `react@^18.3.1`, `@tanstack/react-query@^5.60.5`

### Key server files
- `server/production.js`: primary Express production entry
- `server/api-routes.js`: auxiliary routes
- `server/websocket/real-time-automation.js`: Socket.IO server wrapper (not mounted in production.js)
- AI endpoints and session/message routes defined in `production.js`

### Client files of interest
- `client/src/components/agent/AgentInterface.tsx`: main chat UI
- `client/src/lib/websocket.ts`: raw WebSocket client logic
- Various pages (`agent-chat.tsx`, `browser-chat.tsx`, etc.)

## Phase 2. Issue Identification (no fixes)

### A. WebSockets / Realtime
- Evidence: Client console shows attempts to use WebSockets (`wss://www.onedollaragent.ai/ws` and `/ws/socket.io/`).
- Codebase:
  - Socket.IO server exists in `server/websocket/real-time-automation.js` but is never imported or initialized in `server/production.js`.
  - Raw WebSocket usage also exists in `client/src/lib/websocket.ts` and several pages.
- Impact:
  - 404s on `/ws/socket.io` due to missing Socket.IO server mount.
  - Potential conflict between two strategies: Socket.IO vs raw WebSocket.
- Status: Blocker for any realtime features (live view, automation signals).

### B. Ollama Integration
- Server code in `server/production.js` initializes Ollama client and calls `ollamaClient.chat()` with model default `tinyllama:latest`.
- Internal URL selection logic present; relies on `OLLAMA_INTERNAL_URL` env.
- Endpoint `/api/session/:sessionId/message` prioritizes Ollama; falls back to LocalAI/adapter if present.
- Observed behavior: AI responses returned successfully (per browser logs) — integration appears functional when network path is correct.
- Status: Working when service reachable; requires env correctness and model present.

### C. Frontend ↔ Backend Messaging
- Endpoint: `POST /api/session/:sessionId/message` (server) — confirmed reachable.
- Client: `AgentInterface.tsx` uses React Query mutation to send; `onSuccess` updates cache; then refetches.
- Prior issues observed:
  - Mutation pending loops caused by auto-reset logic (now removed in code).
  - Messages not rendering due to backend returning objects missing required client fields (`id`, `sessionId`, etc.) — server now includes full fields so list rendering has keys and types.
- Current risk: UI still depends on refetch timing; optimistic update added to avoid gaps.
- Status: Non-blocker after schema alignment; requires verification in production.

### D. Other 404s (e.g., `/_app/version.json`)
- Not generated by our Express app; likely a stale asset request from a prior deploy or a framework artifact from a different build target.
- There is no `_app/version.json` in repo; suggests client-side bundle or a historical path referencing Next.js-like artifacts.
- Status: Warning; investigate client runtime references to `_app` assets and ensure Vite build outputs only expected files.

### E. Multiple Realtime Implementations
- Socket.IO server wrapper exists but unused.
- Raw WebSocket logic exists and is used by some pages/components.
- Workers also use WebSockets for VNC streaming.
- Risk: Competing protocols and endpoints increase complexity and 404s when the corresponding server isn’t mounted.
- Status: Architectural inconsistency — Blocker for reliable live view.

### F. Production vs Dev setup
- `server/index.ts` (dev) mentions a WebSocket log line; production relies on `server/production.js` which does not initialize Socket.IO.
- Status: Environments diverge; production lacks realtime init.

## Phase 3. Root Cause Analysis & Dependencies

- Primary realtime root cause: Socket.IO server module exists but is not wired in production; raw WebSocket code expects `/ws` while client logs show `/ws/socket.io/` — mixed strategies cause 404s.
- Messaging display root cause: Backend message schema previously missing required fields; list rendering required `id` and consistent shape.
- Ollama availability depends on:
  - `OLLAMA_INTERNAL_URL` env pointing to correct private DNS (`http://ollama-ai.railway.internal:11434`).
  - Model `tinyllama:latest` pulled in `ollama-service/Dockerfile`.
- Other 404s (`/_app/version.json`) likely from legacy paths or asset references not present in Vite build — separate from chat flow.

Dependencies among issues:
- Realtime features (live view) depend on mounting one realtime strategy (Socket.IO or raw WS) and disabling the conflicting one.
- Chat UI correctness depends on message schema, cache updates, and endpoint health.
- Ollama calls depend on service reachability and correct env values.

## Phase 4. Fix Implementation Plan (not executing yet)

- Realtime:
  - Choose a single strategy (Socket.IO recommended for rooms/events). Mount `RealTimeAutomationSocket` in `production.js` using the HTTP server on path `/ws` or `/ws/socket.io`.
  - Remove or fence off raw WebSocket client paths that point to endpoints without servers.
- Messaging:
  - Maintain server message schema contract; ensure refetch and optimistic UI both function.
- Assets/404s:
  - Search and remove references to `/_app/version.json`; verify Vite build asset paths.
- Ollama:
  - Confirm env var `OLLAMA_INTERNAL_URL` and health `/api/version` from Tagent service; keep model name `tinyllama:latest`.

## Phase 5. Final Verification (to be done after fixes)

- End-to-end test: send message → AI reply → messages render.
- Realtime: open live view → WebSocket connects (no 404) → receive events.
- Health: `/api/health` green; Ollama `/api/version` reachable from private network.

---

## Open Questions
- Why was `real-time-automation.js` authored but never mounted in production? Was it used only in dev/alternate server?
- Do we intend to keep both raw WebSocket and Socket.IO, or consolidate to one?
- What is the intended data flow: chat via HTTP only, realtime via WebSocket, and Ollama strictly server-side?
- Are there any legacy pages still referencing `_app/version.json`?

End of read-only report. Awaiting approval to propose a unified fix plan covering all identified issues.
